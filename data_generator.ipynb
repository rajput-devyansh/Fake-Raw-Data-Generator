{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "727e7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "from src.Generic_Errors import apply_generic_chaos\n",
    "from src.Format_Errors import chaotic_date\n",
    "from src.Format_Errors import chaotic_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d5cf3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ò¢Ô∏è  INITIALIZING DATA Generation (5000 rows/file)...\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION\n",
    "DATASET_SIZE = 5000  # Number of rows per file\n",
    "OUTPUT_DIR = \"Generated_Data\"\n",
    "\n",
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# *** FIX: Define 'rows' globally here ***\n",
    "rows = DATASET_SIZE \n",
    "\n",
    "print(f\"‚ò¢Ô∏è  INITIALIZING DATA Generation ({rows} rows/file)...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90bd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Retail Dataset with 5000 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Fake-Raw-Data-Generator\\src\\Generic_Errors.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, col] = np.nan\n"
     ]
    }
   ],
   "source": [
    "# Retail Dataset \n",
    "print(f\"Generating Retail Dataset with {rows} rows.\")\n",
    "\n",
    "# Expanded list of Categories for more variety\n",
    "categories = ['Electronics', 'Clothing', 'Home', 'Grocery', 'Toys', 'Books']\n",
    "payment_methods = ['Credit Card', 'Cash', 'UPI', 'Debit Card', 'Wallet']\n",
    "\n",
    "df_ret = pd.DataFrame({\n",
    "    \"Trans_ID\": [fake.uuid4()[:8] for _ in range(rows)],\n",
    "    \"Date\": [fake.date_this_year() for _ in range(rows)],\n",
    "    \n",
    "    # --- NEW COLUMNS ---\n",
    "    \"Customer_Name\": [fake.name() for _ in range(rows)],\n",
    "    \"Customer_Email\": [fake.email() for _ in range(rows)],\n",
    "    \"Store_City\": [fake.city() for _ in range(rows)],\n",
    "    \"Payment_Method\": [random.choice(payment_methods) for _ in range(rows)],\n",
    "    \"Is_Member\": [random.choice([True, False]) for _ in range(rows)],\n",
    "    \"Discount_Pct\": [random.choice([0, 0, 0.05, 0.10, 0.15, 0.20, 0.50]) for _ in range(rows)],\n",
    "    # -------------------\n",
    "    \n",
    "    \"Category\": [random.choice(categories) for _ in range(rows)],\n",
    "    \"Qty\": [random.choice([1, 2, 3, 5, 10, 0]) for _ in range(rows)],\n",
    "    \"Price\": [round(random.uniform(10, 500), 2) for _ in range(rows)]\n",
    "})\n",
    "\n",
    "# --- LOGIC UPDATES ---\n",
    "# Calculate Total with Discount applied\n",
    "df_ret[\"Total\"] = (df_ret[\"Price\"] * df_ret[\"Qty\"]) * (1 - df_ret[\"Discount_Pct\"])\n",
    "df_ret[\"Total\"] = df_ret[\"Total\"].round(2)\n",
    "\n",
    "# --- CHAOS INJECTION (Existing & New) ---\n",
    "\n",
    "# 1. Existing Chaos\n",
    "df_ret.loc[0:50, \"Total\"] += 100 \n",
    "df_ret.loc[51:100, \"Qty\"] = -5 \n",
    "df_ret.loc[101:150, \"Date\"] = datetime.date(2099, 1, 1) \n",
    "\n",
    "# 2. New Chaos for new columns\n",
    "# Make some discounts greater than 100% (Math error testing)\n",
    "df_ret.loc[151:170, \"Discount_Pct\"] = 1.50 \n",
    "\n",
    "# Make some Payment Methods NaN/Null\n",
    "df_ret.loc[171:200, \"Payment_Method\"] = None\n",
    "\n",
    "# Corrupt some email formats\n",
    "df_ret.loc[201:220, \"Customer_Email\"] = \"user_at_gmail.com\" # Missing @\n",
    "\n",
    "# 3. Apply Styling Chaos\n",
    "df_ret[\"Category\"] = df_ret[\"Category\"].apply(chaotic_case) \n",
    "df_ret[\"Date\"] = df_ret[\"Date\"].apply(chaotic_date) \n",
    "df_ret = apply_generic_chaos(df_ret)\n",
    "\n",
    "# Export\n",
    "df_ret.to_csv(f\"{OUTPUT_DIR}/01_retail_dataset.csv\", index=False)\n",
    "print(\"Retail Dataset generated and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. FINANCE üí∞\n",
    "print(\"Generating Finance...\")\n",
    "df_fin = pd.DataFrame({\n",
    "    \"App_ID\": [f\"LN-{random.randint(1000,9999)}\" for _ in range(rows)],\n",
    "    \"Income\": [random.randint(-5000, 150000) for _ in range(rows)],\n",
    "    \"Credit_Score\": [random.randint(300, 950) for _ in range(rows)],\n",
    "    \"Debt\": [random.randint(0, 50000) for _ in range(rows)],\n",
    "    \"Status\": [random.choice(['Approved', 'Rejected']) for _ in range(rows)]\n",
    "})\n",
    "df_fin[\"DTI_Ratio\"] = df_fin[\"Debt\"] / df_fin[\"Income\"] \n",
    "bad_idx = df_fin[df_fin[\"Credit_Score\"] < 500].sample(frac=0.2).index\n",
    "df_fin.loc[bad_idx, \"Status\"] = \"Approved\" \n",
    "df_fin = apply_generic_chaos(df_fin)\n",
    "df_fin.to_csv(f\"{OUTPUT_DIR}/02_finance_chaos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f607b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SUPPLY CHAIN üè≠\n",
    "print(\"Generating Supply Chain...\")\n",
    "df_sc = pd.DataFrame({\n",
    "    \"ID\": [fake.bothify('??-####') for _ in range(rows)],\n",
    "    \"Location\": [random.choice([fake.city(), fake.state(), \"USA\", \"India\"]) for _ in range(rows)], \n",
    "    \"Weight\": [f\"{random.randint(10,500)} {random.choice(['kg','lbs','Lbs',''])}\" for _ in range(rows)], \n",
    "    \"Ship_Date\": [fake.date_this_year() for _ in range(rows)],\n",
    "    \"Arrival_Date\": [fake.date_this_year() for _ in range(rows)]\n",
    "})\n",
    "df_sc.loc[0:20, \"Arrival_Date\"] = df_sc.loc[0:20, \"Ship_Date\"] - datetime.timedelta(days=10) \n",
    "df_sc = apply_generic_chaos(df_sc)\n",
    "# Manual Delimiter Injection\n",
    "with open(f\"{OUTPUT_DIR}/03_supply_chain_chaos.csv\", \"a\") as f:\n",
    "    f.write(\"\\nBAD_ROW,New York, NY,50kg,2023-01-01,2023-01-02\") \n",
    "df_sc.to_csv(f\"{OUTPUT_DIR}/03_supply_chain_chaos.csv\", index=False, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c78de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. HEALTHCARE üè•\n",
    "print(\"Generating Healthcare...\")\n",
    "df_hlth = pd.DataFrame({\n",
    "    \"Pid\": range(rows),\n",
    "    \"Age\": [random.randint(1, 150) for _ in range(rows)], \n",
    "    \"Gender\": [random.choice(['M', 'F', 'Male', 'Female', 'm', 'f']) for _ in range(rows)], \n",
    "    \"Admit\": [fake.date_this_year() for _ in range(rows)],\n",
    "    \"Discharge\": [fake.date_this_year() for _ in range(rows)]\n",
    "})\n",
    "bad_dates = df_hlth.sample(frac=0.05).index\n",
    "for i in bad_dates:\n",
    "    df_hlth.at[i, \"Discharge\"] = df_hlth.at[i, \"Admit\"] - datetime.timedelta(days=5)\n",
    "df_hlth = apply_generic_chaos(df_hlth)\n",
    "df_hlth.to_csv(f\"{OUTPUT_DIR}/04_healthcare_chaos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. MARKETING üì¢\n",
    "print(\"Generating Marketing...\")\n",
    "df_mkt = pd.DataFrame({\n",
    "    \"Campaign\": [fake.catch_phrase() for _ in range(rows)],\n",
    "    \"Impressions\": [random.randint(1000, 10000) for _ in range(rows)],\n",
    "    \"Clicks\": [random.randint(100, 5000) for _ in range(rows)],\n",
    "    \"Spend\": [random.randint(-100, 5000) for _ in range(rows)] \n",
    "})\n",
    "bad_mkt = df_mkt.sample(frac=0.1).index\n",
    "df_mkt.loc[bad_mkt, \"Clicks\"] = df_mkt.loc[bad_mkt, \"Impressions\"] + 500 \n",
    "df_mkt = apply_generic_chaos(df_mkt)\n",
    "df_mkt.to_csv(f\"{OUTPUT_DIR}/05_marketing_chaos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dbd0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. HR üë•\n",
    "print(\"Generating HR...\")\n",
    "df_hr = pd.DataFrame({\n",
    "    \"Name\": [fake.name() for _ in range(rows)],\n",
    "    \"Age\": [random.randint(18, 65) for _ in range(rows)],\n",
    "    \"Marital\": [random.choice(['Single', 'Married', 'Divorced']) for _ in range(rows)],\n",
    "    \"Join_Date\": [fake.date_this_year() for _ in range(rows)]\n",
    "})\n",
    "bad_hr = df_hr.sample(20).index\n",
    "df_hr.loc[bad_hr, \"Age\"] = 5\n",
    "df_hr.loc[bad_hr, \"Marital\"] = \"Married\" \n",
    "df_hr.loc[0:10, \"Join_Date\"] = datetime.date(2099, 1, 1) \n",
    "df_hr = apply_generic_chaos(df_hr)\n",
    "df_hr.to_csv(f\"{OUTPUT_DIR}/06_hr_chaos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. LOGISTICS üöö\n",
    "print(\"Generating Logistics...\")\n",
    "df_log = pd.DataFrame({\n",
    "    \"Origin\": [fake.city() for _ in range(rows)],\n",
    "    \"Dest\": [fake.city() for _ in range(rows)],\n",
    "    \"Distance\": [random.randint(0, 5000) for _ in range(rows)],\n",
    "    \"Fuel\": [random.randint(0, 500) for _ in range(rows)]\n",
    "})\n",
    "df_log.loc[0:20, \"Distance\"] = 0 \n",
    "df_log.loc[21:40, \"Origin\"] = df_log.loc[21:40, \"Dest\"] \n",
    "df_log = apply_generic_chaos(df_log)\n",
    "df_log.to_csv(f\"{OUTPUT_DIR}/07_logistics_chaos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf54d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. CUSTOMER SERVICE üéß\n",
    "print(\"Generating CS...\")\n",
    "df_cs = pd.DataFrame({\n",
    "    \"Email\": [fake.email() for _ in range(rows)],\n",
    "    \"Priority\": [random.choice(['High', 'H', 'Low', 'L', 'Medium', 'Med']) for _ in range(rows)],\n",
    "    \"Resolution_Hours\": [random.uniform(-10, 72) for _ in range(rows)] \n",
    "})\n",
    "df_cs = apply_generic_chaos(df_cs)\n",
    "df_cs.to_csv(f\"{OUTPUT_DIR}/08_customer_service_chaos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7436543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. INSURANCE üõ°Ô∏è\n",
    "print(\"Generating Insurance...\")\n",
    "df_ins = pd.DataFrame({\n",
    "    \"Policy\": [random.choice(['Auto', 'Home', 'Life']) for _ in range(rows)],\n",
    "    \"Claim_Amt\": [random.uniform(100, 10000) for _ in range(rows)],\n",
    "    \"Coverage\": [1000 for _ in range(rows)]\n",
    "})\n",
    "df_ins.loc[0:50, \"Claim_Amt\"] = 5000 \n",
    "df_ins = apply_generic_chaos(df_ins)\n",
    "df_ins.to_csv(f\"{OUTPUT_DIR}/09_insurance_chaos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd71442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. REAL ESTATE üè†\n",
    "print(\"Generating Real Estate...\")\n",
    "df_re = pd.DataFrame({\n",
    "    \"Price\": [random.randint(100000, 500000) for _ in range(rows)],\n",
    "    \"Bedrooms\": [random.randint(1, 5) for _ in range(rows)],\n",
    "    \"SqFt\": [random.randint(500, 5000) for _ in range(rows)]\n",
    "})\n",
    "df_re.loc[0:20, \"Price\"] = 0\n",
    "df_re.loc[21:30, \"Bedrooms\"] = 100 \n",
    "df_re.loc[31:40, \"SqFt\"] = -500 \n",
    "df_re = apply_generic_chaos(df_re)\n",
    "df_re.to_csv(f\"{OUTPUT_DIR}/10_real_estate_chaos.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
